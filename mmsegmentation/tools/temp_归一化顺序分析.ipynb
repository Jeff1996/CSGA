{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means聚类过程中，L2归一化的顺序研究\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 设置随机数种子\n",
    "def set_random_seed(seed: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)                           # 固定python的随机策略\n",
    "    np.random.seed(seed)                        # 在使用 Numpy 库取随机数时，需要对其随机数种子进行限制\n",
    "    torch.manual_seed(seed)                     # 当 Pytorch 使用 CPU 进行运算时，需要设定 CPU 支撑下的 Pytorch 随机数种子\n",
    "    torch.cuda.manual_seed(seed)                # 单 GPU 情况\n",
    "    torch.cuda.manual_seed_all(seed)            # 多 GPU 情况\n",
    "    try:\n",
    "        torch.backends.cudnn.benchmark = False  # 限制 Cudnn 在加速过程中涉及到的随机策略\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# set_random_seed(0)\n",
    "\n",
    "batch_size = 1\n",
    "L = 4\n",
    "dim = 8\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    # nn.Linear(dim, dim, bias=False),\n",
    "    nn.GELU(), \n",
    ")\n",
    "\n",
    "data = torch.randn((batch_size, L, dim))\n",
    "data = net(data)\n",
    "print('data: \\n', data)\n",
    "\n",
    "# 1. 先归一化k矩阵，再构造聚类中心、k-means聚类\n",
    "data_norm = F.normalize(data, dim=-1)                               # [B, L, dim]\n",
    "print('data_norm: \\n', data_norm)\n",
    "\n",
    "center_prenorm = F.normalize(data_norm.sum(dim=-2, keepdim=True), dim=-1)   # [B, S, dim]\n",
    "print('pre-normal center: \\n', center_prenorm)\n",
    "\n",
    "# 2. 先构造聚类中心，在对k矩阵、聚类中心进行归一化\n",
    "center_postnorm = F.normalize(data.sum(dim=-2, keepdim=True), dim=-1) \n",
    "print('post-normal center: \\n', center_postnorm)\n",
    "\n",
    "cosim = torch.einsum('bld,bsd->bls', center_prenorm, center_postnorm)\n",
    "print('cosim: \\n', cosim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_index: \n",
      " tensor([0, 0, 9, 1])\n",
      "affinity: \n",
      " tensor([[0.7410, 0.8091, 0.5262, 0.3495]])\n"
     ]
    }
   ],
   "source": [
    "# 特征单位化的元素相加，其归一化和与原始元素的余弦相似度研究\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 设置随机数种子\n",
    "def set_random_seed(seed: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)                           # 固定python的随机策略\n",
    "    np.random.seed(seed)                        # 在使用 Numpy 库取随机数时，需要对其随机数种子进行限制\n",
    "    torch.manual_seed(seed)                     # 当 Pytorch 使用 CPU 进行运算时，需要设定 CPU 支撑下的 Pytorch 随机数种子\n",
    "    torch.cuda.manual_seed(seed)                # 单 GPU 情况\n",
    "    torch.cuda.manual_seed_all(seed)            # 多 GPU 情况\n",
    "    try:\n",
    "        torch.backends.cudnn.benchmark = False  # 限制 Cudnn 在加速过程中涉及到的随机策略\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# set_random_seed(0)\n",
    "\n",
    "batch_size = 1\n",
    "L = 4\n",
    "dim = 8\n",
    "num_class = 10\n",
    "\n",
    "data_index = torch.tensor([0, 0, 9, 1])\n",
    "# data_index = torch.randint(0, num_class, (L, ))\n",
    "print('data_index: \\n', data_index)\n",
    "\n",
    "eyes = torch.eye(num_class)\n",
    "data_onehot = eyes[data_index]                                            # [L, dim]\n",
    "data_noise = torch.randn_like(data_onehot) * 0.1\n",
    "# data_noise = torch.zeros_like(data_onehot)\n",
    "data = F.normalize(data_onehot + data_noise)\n",
    "# print('data: \\n', data)\n",
    "\n",
    "center = F.normalize(data.sum(dim=0, keepdim=True), dim=-1)  # [1, dim]\n",
    "affinity = torch.einsum('ld,sd->sl', data, center)\n",
    "print('affinity: \\n', affinity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
