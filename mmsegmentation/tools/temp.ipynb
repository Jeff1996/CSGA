{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5)  # 浅层\n",
    "        self.layer2 = nn.Linear(5, 5)   # 中间层，将被冻结\n",
    "        self.layer3 = nn.Linear(5, 2)   # 深层\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))  # 中间层输出\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleModel()\n",
    "\n",
    "# 冻结中间层的参数\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer2' in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# 创建优化器，只包括浅层和深层的参数\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "\n",
    "# 示例输入和目标\n",
    "input_data = torch.randn(1, 10)\n",
    "target_data = torch.randn(1, 2)\n",
    "\n",
    "# 损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 训练步骤\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "output = model(input_data)\n",
    "loss = criterion(output, target_data)\n",
    "loss.backward()  # 计算所有可训练参数的梯度，冻结层的参数不会计算梯度\n",
    "optimizer.step()  # 更新浅层和深层的参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
