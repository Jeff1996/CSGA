{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n",
      "tensor([[1.0000, 0.3679, 0.1353, 0.3679, 0.2431, 0.1069, 0.1353, 0.1069, 0.0591],\n",
      "        [0.3679, 1.0000, 0.3679, 0.2431, 0.3679, 0.2431, 0.1069, 0.1353, 0.1069],\n",
      "        [0.1353, 0.3679, 1.0000, 0.1069, 0.2431, 0.3679, 0.0591, 0.1069, 0.1353],\n",
      "        [0.3679, 0.2431, 0.1069, 1.0000, 0.3679, 0.1353, 0.3679, 0.2431, 0.1069],\n",
      "        [0.2431, 0.3679, 0.2431, 0.3679, 1.0000, 0.3679, 0.2431, 0.3679, 0.2431],\n",
      "        [0.1069, 0.2431, 0.3679, 0.1353, 0.3679, 1.0000, 0.1069, 0.2431, 0.3679],\n",
      "        [0.1353, 0.1069, 0.0591, 0.3679, 0.2431, 0.1069, 1.0000, 0.3679, 0.1353],\n",
      "        [0.1069, 0.1353, 0.1069, 0.2431, 0.3679, 0.2431, 0.3679, 1.0000, 0.3679],\n",
      "        [0.0591, 0.1069, 0.1353, 0.1069, 0.2431, 0.3679, 0.1353, 0.3679, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 使用线性插值算法构造相对位置编码\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化相对位置编码\n",
    "def initRPE(size_src: tuple, size_tar: tuple, device: torch.device='cpu', gain: float=1.0):\n",
    "    '''\n",
    "    size: 特征图尺寸, (h, w)\n",
    "    index_onehot: 聚类结果(每个像素对应的聚类中心的one-hot索引), [B, num_heads, L, S]\n",
    "    gain: 增益系数\n",
    "    '''\n",
    "    assert type(size_src) == tuple, 'Data type of size in function <initRPE> should be <tuple>!'\n",
    "    assert size_src.__len__() == 2, 'Length of size should be 2!'\n",
    "    # 构造基础坐标系, 左上角像素中心坐标为(0.5, 0.5)\n",
    "    H_max = max(size_src[0], size_tar[0])\n",
    "    W_max = max(size_src[1], size_tar[1])\n",
    "    coords_h = torch.arange(H_max) + 0.5                    # 以更大尺寸构造行坐标系，行坐标与例坐标分开，更加鲁棒\n",
    "    coords_w = torch.arange(W_max) + 0.5                    # 以更大尺寸构造列坐标系\n",
    "    coords_base = torch.stack(\n",
    "        torch.meshgrid([coords_h, coords_w])                # 构造基础坐标网格，[2, h, w]\n",
    "    ).unsqueeze(0).float()                                  # [1, 2, h, w], unsqueeze是为了插值\n",
    "    # 获取原图各像素点坐标\n",
    "    if size_src == (H_max, W_max):\n",
    "        coords_src = coords_base\n",
    "    else:\n",
    "        coords_src = F.interpolate(coords_base, size_src, mode='bilinear')\n",
    "    # 获取目标图各像素点坐标\n",
    "    if size_tar == (H_max, W_max):\n",
    "        coords_tar = coords_base\n",
    "    else:\n",
    "        coords_tar = F.interpolate(coords_base, size_tar, mode='bilinear')\n",
    "    # 一维化坐标，便于计算相对位置\n",
    "    coords_src = coords_src.reshape(2, -1).to(device)       # [2, L]\n",
    "    coords_tar = coords_tar.reshape(2, -1).to(device)       # [2, S]\n",
    "    # 构造相对位置矩阵, 第一个矩阵是h方向的相对位置差, 第二个矩阵是w方向的相对位置差\n",
    "    relative_coords = coords_src[:, :, None] - coords_tar[:, None, :]   # [2, L, S]\n",
    "    distance = torch.sqrt(                                              # [L, S]\n",
    "        torch.square(relative_coords[0,:,:]) + torch.square(relative_coords[1,:,:])\n",
    "    )\n",
    "    # exp操作用于处理distance中的0, [B, num_heads, L, S]\n",
    "    distance_exp = torch.exp(distance)\n",
    "    # 距离越远的token注意力增强越少(加性增强), 最大值为1*gain, 最小值可以接近0, [L, S]\n",
    "    rpe = (1 / distance_exp) * gain\n",
    "    return rpe\n",
    "\n",
    "size_src = (3, 3)\n",
    "size_tar = (3, 3)\n",
    "\n",
    "rpe = initRPE(size_src, size_tar)\n",
    "print(rpe.shape)\n",
    "print(rpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Union\n",
    "\n",
    "def func(a=None, b=None) -> int:\n",
    "    assert a is None or b is None, '不能同时指定a和b'\n",
    "    if not a is None:\n",
    "        return a\n",
    "    elif not b is None:\n",
    "        return b\n",
    "    else:\n",
    "        pass\n",
    "# func(a=1, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_index_x: \n",
      " tensor([[[[0, 0, 0, 1, 1],\n",
      "          [0, 0, 0, 1, 1],\n",
      "          [0, 0, 0, 1, 1],\n",
      "          [2, 2, 2, 3, 3],\n",
      "          [2, 2, 2, 3, 3]]]])\n",
      "delta_onehot_x: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "delta_onehot_pad_x: \n",
      " torch.Size([1, 4, 6, 7])\n",
      "delta_index_pad_x: \n",
      " tensor([[[0, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 1, 1, 1, 0],\n",
      "         [2, 2, 2, 3, 3, 3, 2],\n",
      "         [2, 2, 2, 3, 3, 3, 2],\n",
      "         [2, 2, 2, 3, 3, 3, 2]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "shape_x = (5, 5)\n",
    "shape_c = (2, 2)\n",
    "\n",
    "delta_index_c = torch.arange(0, shape_c[0]*shape_c[1]).reshape(1, 1, *shape_c).float()  # [1, 1, H_c, W_c]\n",
    "delta_index_x = F.interpolate(delta_index_c, shape_x, mode='nearest').long()            # [1, 1, H_x, W_x]\n",
    "delta_onehot_x = F.one_hot(delta_index_x, shape_c[0]*shape_c[1]).permute(0, 1, 4, 2, 3).reshape(1, shape_c[0]*shape_c[1], *shape_x).float() # [1, S, H_x, W_x]\n",
    "\n",
    "delta_onehot_pad_x = F.pad(delta_onehot_x, (0, 2, 0, 1), mode='reflect')\n",
    "delta_index_pad_x = delta_onehot_pad_x.argmax(dim=1)\n",
    "\n",
    "# print('delta_index_c: \\n', delta_index_c)\n",
    "print('delta_index_x: \\n', delta_index_x)\n",
    "print('delta_onehot_x: \\n', delta_onehot_x.shape)\n",
    "# print('delta_onehot_x: \\n', delta_onehot_x)\n",
    "\n",
    "print('delta_onehot_pad_x: \\n', delta_onehot_pad_x.shape)\n",
    "print('delta_index_pad_x: \\n', delta_index_pad_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]])\n",
      "tensor([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.zeros((4, 2)) * 10\n",
    "b = a.sum(dim=0, keepdim=True) / a.shape[0]\n",
    "c = a.sum(dim=0, keepdim=True)\n",
    "\n",
    "print(F.normalize(b))\n",
    "print(F.normalize(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([0, 1], dtype=torch.float32)\n",
    "b = torch.tensor([torch.inf, torch.inf], dtype=torch.float32)\n",
    "\n",
    "dist = (a - b).square().sum().sqrt()\n",
    "print(1/dist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hjf_mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
