{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.stages.0.blocks.0.attn.w_msa.scale: 6.0884\n",
      "backbone.stages.0.blocks.1.attn.w_msa.scale: 26.9105\n",
      "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 8.0664\n",
      "backbone.stages.1.blocks.0.attn.w_msa.scale: 5.3904\n",
      "backbone.stages.1.blocks.1.attn.w_msa.scale: 25.8426\n",
      "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 7.9613\n",
      "backbone.stages.2.blocks.0.attn.w_msa.scale: 7.1399\n",
      "backbone.stages.2.blocks.1.attn.w_msa.scale: 19.5820\n",
      "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 8.0745\n",
      "backbone.stages.2.blocks.2.attn.w_msa.scale: 8.4336\n",
      "backbone.stages.2.blocks.3.attn.w_msa.scale: 14.7162\n",
      "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 7.7266\n",
      "backbone.stages.2.blocks.4.attn.w_msa.scale: 10.7921\n",
      "backbone.stages.2.blocks.5.attn.w_msa.scale: 13.0888\n",
      "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 7.6404\n",
      "backbone.stages.3.blocks.0.attn.w_msa.scale: 13.9363\n",
      "backbone.stages.3.blocks.1.attn.w_msa.scale: 10.6370\n",
      "backbone.stages.3.blocks.1.attn.w_msa.cluster.scale: 8.1501\n"
     ]
    }
   ],
   "source": [
    "# 权重分析\n",
    "import torch\n",
    "\n",
    "'''\n",
    "引入affinity loss, 学习率衰减指数为2, batch_size = 8, accumulative_counts = 2, iters = 160k, mIoU: 41.16\n",
    "/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/20241211_153905/20241211_153905.log\n",
    "backbone.stages.0.blocks.0.attn.w_msa.scale: 7.9995\n",
    "backbone.stages.0.blocks.1.attn.w_msa.scale: 18.5892\n",
    "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 14.2719\n",
    "backbone.stages.1.blocks.0.attn.w_msa.scale: 7.4918\n",
    "backbone.stages.1.blocks.1.attn.w_msa.scale: 24.6085\n",
    "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 15.2827\n",
    "backbone.stages.2.blocks.0.attn.w_msa.scale: 8.8867\n",
    "backbone.stages.2.blocks.1.attn.w_msa.scale: 24.6206\n",
    "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 14.9126\n",
    "backbone.stages.2.blocks.2.attn.w_msa.scale: 10.3616\n",
    "backbone.stages.2.blocks.3.attn.w_msa.scale: 22.1253\n",
    "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 14.1763\n",
    "backbone.stages.2.blocks.4.attn.w_msa.scale: 13.2011\n",
    "backbone.stages.2.blocks.5.attn.w_msa.scale: 21.1886\n",
    "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 14.8000\n",
    "backbone.stages.3.blocks.0.attn.w_msa.scale: 14.1448\n",
    "backbone.stages.3.blocks.1.attn.w_msa.scale: 13.2135\n",
    "\n",
    "引入affinity loss, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, mIoU: 42.10\n",
    "/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/20241212_181706/20241212_181706.log\n",
    "backbone.stages.0.blocks.0.attn.w_msa.scale: 7.4283\n",
    "backbone.stages.0.blocks.1.attn.w_msa.scale: 18.6118\n",
    "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 13.8546\n",
    "backbone.stages.1.blocks.0.attn.w_msa.scale: 6.4046\n",
    "backbone.stages.1.blocks.1.attn.w_msa.scale: 27.1329\n",
    "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 14.9124\n",
    "backbone.stages.2.blocks.0.attn.w_msa.scale: 8.4448\n",
    "backbone.stages.2.blocks.1.attn.w_msa.scale: 30.2003\n",
    "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 14.7124\n",
    "backbone.stages.2.blocks.2.attn.w_msa.scale: 10.6913\n",
    "backbone.stages.2.blocks.3.attn.w_msa.scale: 25.0890\n",
    "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 13.4440\n",
    "backbone.stages.2.blocks.4.attn.w_msa.scale: 13.5143\n",
    "backbone.stages.2.blocks.5.attn.w_msa.scale: 23.2607\n",
    "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 13.8519\n",
    "backbone.stages.3.blocks.0.attn.w_msa.scale: 15.8173\n",
    "backbone.stages.3.blocks.1.attn.w_msa.scale: 13.4283\n",
    "\n",
    "引入affinity loss, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 42.10\n",
    "backbone.stages.0.blocks.0.attn.w_msa.scale: 7.4350\n",
    "backbone.stages.0.blocks.1.attn.w_msa.scale: 19.0621\n",
    "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 14.8756\n",
    "backbone.stages.1.blocks.0.attn.w_msa.scale: 6.5290\n",
    "backbone.stages.1.blocks.1.attn.w_msa.scale: 26.0960\n",
    "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 15.4253\n",
    "backbone.stages.2.blocks.0.attn.w_msa.scale: 8.5122\n",
    "backbone.stages.2.blocks.1.attn.w_msa.scale: 28.0418\n",
    "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 15.3164\n",
    "backbone.stages.2.blocks.2.attn.w_msa.scale: 10.8095\n",
    "backbone.stages.2.blocks.3.attn.w_msa.scale: 24.5086\n",
    "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 14.6441\n",
    "backbone.stages.2.blocks.4.attn.w_msa.scale: 13.8314\n",
    "backbone.stages.2.blocks.5.attn.w_msa.scale: 22.5867\n",
    "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 15.2787\n",
    "backbone.stages.3.blocks.0.attn.w_msa.scale: 15.2816\n",
    "backbone.stages.3.blocks.1.attn.w_msa.scale: 13.1493\n",
    "\n",
    "取消affinity loss, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 42.69\n",
    "/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/20241215_200234/20241215_200234.log\n",
    "backbone.stages.0.blocks.0.attn.w_msa.scale: 7.2431\n",
    "backbone.stages.0.blocks.1.attn.w_msa.scale: 16.6175\n",
    "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 14.2882\n",
    "backbone.stages.1.blocks.0.attn.w_msa.scale: 6.2047\n",
    "backbone.stages.1.blocks.1.attn.w_msa.scale: 20.8416\n",
    "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 15.4718\n",
    "backbone.stages.2.blocks.0.attn.w_msa.scale: 8.0125\n",
    "backbone.stages.2.blocks.1.attn.w_msa.scale: 19.0302\n",
    "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 14.7202\n",
    "backbone.stages.2.blocks.2.attn.w_msa.scale: 9.7666\n",
    "backbone.stages.2.blocks.3.attn.w_msa.scale: 15.8681\n",
    "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 14.3533\n",
    "backbone.stages.2.blocks.4.attn.w_msa.scale: 12.6336\n",
    "backbone.stages.2.blocks.5.attn.w_msa.scale: 14.4990\n",
    "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 14.5599\n",
    "backbone.stages.3.blocks.0.attn.w_msa.scale: 14.8858\n",
    "backbone.stages.3.blocks.1.attn.w_msa.scale: 12.8946\n",
    "\n",
    "引入affinity loss, 仅在聚类过程单位化k矩阵的token, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 41.87\n",
    "/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/20241220_112039/20241220_112039.log\n",
    "backbone.stages.0.blocks.1.attn.w_msa.cluster.scale: 30.2690\n",
    "backbone.stages.1.blocks.1.attn.w_msa.cluster.scale: 29.5008\n",
    "backbone.stages.2.blocks.1.attn.w_msa.cluster.scale: 30.2166\n",
    "backbone.stages.2.blocks.3.attn.w_msa.cluster.scale: 30.2710\n",
    "backbone.stages.2.blocks.5.attn.w_msa.cluster.scale: 30.1993\n",
    "\n",
    "取消affinity loss, 使用分割标签构造, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 42.57 -> 43.96(中心裁剪，固定验证集尺寸为正方形, 涨点1.39) -> 42.66(调整横纵比，resize为正方形)\n",
    "swin-t原生                                                                                                                          44.41 -> 44.94                                          -> 43.45\n",
    "\n",
    "1225架构, 取消affinity loss, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 43.40 -> 44.37(中心裁剪，固定验证集尺寸为正方形, 涨点0.97) -> \n",
    "\n",
    "1230架构, 取消affinity loss, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, scale系数无正则化, mIoU: 43.15 -> 43.92(中心裁剪，固定验证集尺寸为正方形, 涨点0.87) -> 43.38(滑窗分割)\n",
    "\n",
    "0104架构, 取消affinity loss, 取消相对位置编码, 学习率衰减指数为1, batch_size = 8, accumulative_counts = 1, iters = 160k, mIoU: 43.75(不使用FlashAttention提速43.77, 再加入相对位置编码43.82) -> 43.87(中心裁剪，固定验证集尺寸为正方形, 涨点0.12) -> 43.86(滑窗分割, 不使用FA提速43.84, 再加入相对位置编码43.88)\n",
    "'''\n",
    "\n",
    "# 引入affinity loss的训练结果41.16\n",
    "path_params = '/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/iter_160000.pth'\n",
    "# path_params = '/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb8-160k_ade20k-512x512/iter_80000.pth'\n",
    "# path_params = '/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb1-80k_ade20k-512x512/epoch_50_聚类_无量化损失_80.672.pth'\n",
    "# path_params = '/home/hjf/workspace/mmsegmentation/work_dirs/swin-tiny-patch4-window7-LN_upernet_2xb1-80k_ade20k-512x512/epoch_50.pth'\n",
    "\n",
    "params = torch.load(path_params)['state_dict']\n",
    "\n",
    "for key in params.keys():\n",
    "    if 'scale' in key:\n",
    "        print('{}: {:.4f}'.format(key, params[key]*15.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.],\n",
      "        [5.]])\n",
      "x1 == x2?  tensor(True)\n",
      "x1 == x3?  tensor(True)\n",
      "x2 == x3?  tensor(True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "L = 10\n",
    "S = 2\n",
    "dim = 3\n",
    "\n",
    "q = torch.randn((L, dim))\n",
    "q = F.normalize(q, dim=-1)\n",
    "k = torch.randn((L, dim))\n",
    "k = F.normalize(k, dim=-1)\n",
    "v = torch.randn((L, dim))\n",
    "\n",
    "delta = torch.randint(0, S, (L, ))                              # [L, ]\n",
    "# delta = torch.tensor([1, 1, 1, 1])\n",
    "# print(delta)\n",
    "delta_onehot = F.one_hot(delta, S).float().transpose(-2, -1)    # [S, L]\n",
    "delta_onehot_sum = delta_onehot.sum(dim=-1, keepdim=True)       # [S, 1]\n",
    "print(delta_onehot_sum)\n",
    "delta_onehot_sum[delta_onehot_sum==0] = 1\n",
    "\n",
    "k_c = torch.einsum('sl,ld->sd', delta_onehot, k)\n",
    "k_c = F.normalize(k_c, dim=-1)\n",
    "v_c = torch.einsum('sl,ld->sd', delta_onehot, v)\n",
    "v_c = v_c / delta_onehot_sum\n",
    "\n",
    "# --- k/v同时下采样的做法 ---\n",
    "attn = F.softmax(q @ k_c.T, dim=-1)\n",
    "x1 =  attn @ v_c\n",
    "\n",
    "# --- 量化k做法 ---\n",
    "k_hat = torch.einsum('sl,sd->ld', delta_onehot, k_c)\n",
    "attn = F.softmax(q @ k_hat.T, dim=-1)\n",
    "x2 = attn @ v\n",
    "\n",
    "# --- 量化k做法 ---\n",
    "qcT = torch.einsum('ld,sd->ls', q, k_c)\n",
    "qcT_exp = torch.exp(qcT)\n",
    "deltaTv = torch.einsum('sl,ld->sd', delta_onehot, v)\n",
    "numerator = torch.einsum('ls,sd->ld', qcT_exp, deltaTv)\n",
    "deltaT1 = torch.einsum('sl->s', delta_onehot)\n",
    "denominator = torch.einsum('ls,s->l', qcT_exp, deltaT1).unsqueeze(-1)\n",
    "denominator[denominator==0] = 1e-6                              # 防止除以0\n",
    "x3 = numerator / denominator\n",
    "\n",
    "print('x1 == x2? ', torch.all((x1-x2).abs() < 1e-6))\n",
    "print('x1 == x3? ', torch.all((x1-x3).abs() < 1e-6))\n",
    "print('x2 == x3? ', torch.all((x2-x3).abs() < 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# vit 预训练权重键名修改\n",
    "import torch\n",
    "\n",
    "path_root = '/home/hjf/workspace/mmsegmentation/work_dirs/pretrained_in1k/01vit'\n",
    "path_src = path_root + '/epoch_50.pth'\n",
    "path_ref = '/home/hjf/workspace/mmsegmentation/work_dirs/pretrained_ade20k/01vit/upernet_vit-b16_ln_mln_512x512_160k_ade20k_20210621_172828-f444c077.pth'\n",
    "\n",
    "# 保存键名，人工分析\n",
    "params = torch.load(path_src, map_location='cpu')['state_dict']\n",
    "with open(path_root+'/weights_vit_cls.txt', 'w', encoding='utf-8') as f:\n",
    "    for key in params.keys():\n",
    "        f.writelines(key + '\\n')\n",
    "\n",
    "params = torch.load(path_ref, map_location='cpu')['state_dict']\n",
    "with open(path_root+'/weights_vit_ref.txt', 'w', encoding='utf-8') as f:\n",
    "    for key in params.keys():\n",
    "        f.writelines(key + '\\n')\n",
    "\n",
    "# 修改键名\n",
    "path_out = path_root + '/epoch_50_seg.pth'\n",
    "params = torch.load(path_src, map_location='cpu')['state_dict']\n",
    "params_out = {}\n",
    "prefix = 'backbone.'\n",
    "rules = {'backbone.': '', 'attn.qkv.': 'attn.attn.in_proj_','attn.proj': 'attn.attn.out_proj'}\n",
    "for key in params:\n",
    "    if not prefix in key:\n",
    "        continue\n",
    "    key_new = key\n",
    "    for rule in rules.keys():\n",
    "        if rule in key_new:\n",
    "            key_new = key_new.replace(rule, rules[rule])\n",
    "    params_out[key_new] = params[key]\n",
    "torch.save(params_out, path_out)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查键值\n",
    "import torch\n",
    "path_out = '/home/hjf/workspace/mmsegmentation/work_dirs/pretrained_in1k/01vit/epoch_50_seg.pth'\n",
    "params = torch.load(path_out, map_location='cpu')\n",
    "with open(path_root + '/weights_vit_seg.txt', 'w', encoding='utf-8') as f:\n",
    "    for key in params.keys():\n",
    "        f.writelines(key + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 检查swin-t在ImageNet-1K上的预训练权重\n",
    "import os\n",
    "import torch\n",
    "path_src = '/home/hjf/workspace/mmsegmentation/work_dirs/pretrained_in1k/04swin/epoch_50.pth'\n",
    "path_out = os.path.dirname(path_src) + '/weights_swin_cls.txt'\n",
    "params = torch.load(path_src, map_location='cpu')\n",
    "with open(path_out, 'w', encoding='utf-8') as f:\n",
    "    for key in params.keys():\n",
    "        f.writelines(key + '\\n')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 检查swin-t官方在ade20k上的训练权重\n",
    "import os\n",
    "import torch\n",
    "path_src = '/home/hjf/workspace/mmsegmentation/work_dirs/pretrained_ade20k/04swin/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth'\n",
    "path_out = os.path.dirname(path_src) + '/weights_swin_seg.txt'\n",
    "params = torch.load(path_src, map_location='cpu')\n",
    "with open(path_out, 'w', encoding='utf-8') as f:\n",
    "    for key in params.keys():\n",
    "        f.writelines(key + '\\n')\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hjf_mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
